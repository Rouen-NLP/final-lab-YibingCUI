{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final TP - NLP\n",
    "## Classification des documents du procès des groupes américains du tabac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['120', '265', '620', '599', '261', '567', '230', '431', '188', '201']\n"
     ]
    }
   ],
   "source": [
    "path = \"Tobacco3482-OCR/\"\n",
    "classes = os.listdir(path)\n",
    "\n",
    "nb = []\n",
    "x = []\n",
    "y = []\n",
    "for cls in classes:\n",
    "    files = os.listdir(path + cls)\n",
    "    for file in files:\n",
    "        with open(path + cls + \"/\" + file, 'r') as f:\n",
    "            txt = f.read()\n",
    "        x.append(txt)\n",
    "        y.append(cls)\n",
    "    nb.append(str(len(files)))\n",
    "print(str(nb))\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "#print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace the \\n with space\n",
    "for i in range(x.shape[0]):\n",
    "    x[i] = x[i].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of texts' lengthes\n",
    "x_token = []\n",
    "for text in x:\n",
    "    tokens = text.split()\n",
    "    x_token.append(tokens)\n",
    "#print(x[0])\n",
    "#print(x_token[0])\n",
    "lengthes = []\n",
    "for i in range(len(x)):\n",
    "    lengthes.append(len(x_token[i]))\n",
    "plt.title('Histogramme de la longeur des documents')\n",
    "plt.hist(lengthes)\n",
    "plt.savefig('histo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create document vectors\n",
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "vectorizer.fit(x_train)\n",
    "x_train_counts = vectorizer.transform(x_train)\n",
    "x_test_counts = vectorizer.transform(x_test)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# With TF-IDF representation\n",
    "tf_transformer = TfidfTransformer()\n",
    "tfidf = tf_transformer.fit(x_train_counts)\n",
    "x_train_tf = tfidf.transform(x_train_counts)\n",
    "x_test_tf = tfidf.transform(x_test_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray of NB: 0.6944045911047346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_tf, y_train)\n",
    "res = clf.score(x_test_tf, y_test)\n",
    "print('Accuray of NB: ' + str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.73      0.49      0.59        45\n",
      "        Email       0.91      0.95      0.93       128\n",
      "         Form       0.69      0.80      0.74        96\n",
      "       Letter       0.58      0.77      0.66       104\n",
      "         Memo       0.54      0.87      0.66       119\n",
      "         News       0.80      0.53      0.64        30\n",
      "         Note       0.50      0.03      0.05        40\n",
      "       Report       1.00      0.06      0.11        50\n",
      "       Resume       1.00      0.97      0.98        31\n",
      "   Scientific       0.81      0.56      0.66        54\n",
      "\n",
      "    micro avg       0.69      0.69      0.69       697\n",
      "    macro avg       0.76      0.60      0.60       697\n",
      " weighted avg       0.73      0.69      0.66       697\n",
      "\n",
      "[[ 22   2   3   7  10   0   1   0   0   0]\n",
      " [  0 122   0   4   2   0   0   0   0   0]\n",
      " [  1   1  77   5  12   0   0   0   0   0]\n",
      " [  0   1   0  80  22   0   0   0   0   1]\n",
      " [  0   2   2  10 103   0   0   0   0   2]\n",
      " [  4   0   3   5   1  16   0   0   0   1]\n",
      " [  2   5  17   3  12   0   1   0   0   0]\n",
      " [  0   1   3  19  18   3   0   3   0   3]\n",
      " [  0   0   1   0   0   0   0   0  30   0]\n",
      " [  1   0   6   5  11   1   0   0   0  30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# YOUR CODE HERE\n",
    "y_pred = clf.predict(x_test_tf)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from nn_utils import TrainingHistory\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import GRU, Dropout, MaxPooling1D, Conv1D, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "import itertools\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             precision_recall_fscore_support, \n",
    "                             accuracy_score)\n",
    "\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN avec représentation TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "MAX_FEATURES = 10000\n",
    "MAX_TEXT_LENGTH = 500\n",
    "#EMBED_SIZE  = 300\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.1\n",
    "NB_CLASS = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf = x_train_tf.toarray()\n",
    "x_train_tf = np.reshape(x_train_tf, (x_train_tf.shape[0], x_train_tf.shape[1], 1))\n",
    "x_test_tf = x_test_tf.toarray()\n",
    "x_test_tf = np.reshape(x_test_tf, (x_test_tf.shape[0], x_test_tf.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Advertisement' 'Email' 'Form' 'Letter' 'Memo' 'News' 'Note' 'Report'\n",
      " 'Resume' 'Scientific']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2000, 1)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2000, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2000, 64)          192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              65537024  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 65,547,466\n",
      "Trainable params: 65,547,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2506 samples, validate on 279 samples\n",
      "Epoch 1/20\n",
      "2506/2506 [==============================] - 173s 69ms/step - loss: 1.3451 - acc: 0.5599 - val_loss: 0.8938 - val_acc: 0.6918\n",
      "Epoch 2/20\n",
      "2506/2506 [==============================] - 186s 74ms/step - loss: 0.7612 - acc: 0.7506 - val_loss: 0.8588 - val_acc: 0.7025\n",
      "Epoch 3/20\n",
      "2506/2506 [==============================] - 180s 72ms/step - loss: 0.6048 - acc: 0.7941 - val_loss: 0.7912 - val_acc: 0.7276\n",
      "Epoch 4/20\n",
      "2506/2506 [==============================] - 181s 72ms/step - loss: 0.5210 - acc: 0.8272 - val_loss: 0.7951 - val_acc: 0.7312\n",
      "Epoch 5/20\n",
      "2506/2506 [==============================] - 182s 73ms/step - loss: 0.4728 - acc: 0.8328 - val_loss: 0.8553 - val_acc: 0.7204\n",
      "Epoch 6/20\n",
      "2506/2506 [==============================] - 155s 62ms/step - loss: 0.4297 - acc: 0.8500 - val_loss: 0.8323 - val_acc: 0.7168\n",
      "Epoch 7/20\n",
      "2506/2506 [==============================] - 153s 61ms/step - loss: 0.3441 - acc: 0.8787 - val_loss: 0.7786 - val_acc: 0.7527\n",
      "Epoch 8/20\n",
      "2506/2506 [==============================] - 144s 57ms/step - loss: 0.3245 - acc: 0.8791 - val_loss: 0.8032 - val_acc: 0.7276\n",
      "Epoch 9/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.3226 - acc: 0.8875 - val_loss: 0.7956 - val_acc: 0.7348\n",
      "Epoch 10/20\n",
      "2506/2506 [==============================] - 138s 55ms/step - loss: 0.2644 - acc: 0.9066 - val_loss: 0.8448 - val_acc: 0.7133\n",
      "Epoch 11/20\n",
      "2506/2506 [==============================] - 138s 55ms/step - loss: 0.2681 - acc: 0.8994 - val_loss: 0.8259 - val_acc: 0.7599\n",
      "Epoch 12/20\n",
      "2506/2506 [==============================] - 138s 55ms/step - loss: 0.2453 - acc: 0.9110 - val_loss: 0.8374 - val_acc: 0.7491\n",
      "Epoch 13/20\n",
      "2506/2506 [==============================] - 138s 55ms/step - loss: 0.2186 - acc: 0.9226 - val_loss: 0.8907 - val_acc: 0.7455\n",
      "Epoch 14/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.1984 - acc: 0.9318 - val_loss: 0.9754 - val_acc: 0.7348\n",
      "Epoch 15/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.2030 - acc: 0.9270 - val_loss: 0.9115 - val_acc: 0.7240\n",
      "Epoch 16/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.2002 - acc: 0.9385 - val_loss: 0.9064 - val_acc: 0.6953\n",
      "Epoch 17/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.2017 - acc: 0.9342 - val_loss: 0.8913 - val_acc: 0.7168\n",
      "Epoch 18/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.1907 - acc: 0.9358 - val_loss: 0.8929 - val_acc: 0.7312\n",
      "Epoch 19/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.1721 - acc: 0.9346 - val_loss: 0.9863 - val_acc: 0.7204\n",
      "Epoch 20/20\n",
      "2506/2506 [==============================] - 139s 55ms/step - loss: 0.1784 - acc: 0.9397 - val_loss: 0.9736 - val_acc: 0.7133\n",
      "Test Accuracy: 0.7747489239598279\n",
      "p r f1 77.5 77.47 77.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74        45\n",
      "           1       0.96      0.93      0.94       128\n",
      "           2       0.86      0.79      0.83        96\n",
      "           3       0.68      0.83      0.75       104\n",
      "           4       0.77      0.83      0.80       119\n",
      "           5       0.54      0.83      0.66        30\n",
      "           6       0.67      0.65      0.66        40\n",
      "           7       0.59      0.20      0.30        50\n",
      "           8       1.00      0.97      0.98        31\n",
      "           9       0.65      0.69      0.67        54\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       697\n",
      "   macro avg       0.75      0.74      0.73       697\n",
      "weighted avg       0.78      0.77      0.77       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,1))\n",
    "    #model = Embedding(MAX_FEATURES, EMBED_SIZE)(inp)\n",
    "    model = Dropout(0.5)(inp)\n",
    "    model = Conv1D(filters=64, kernel_size=2, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=2)(model)\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(NB_CLASS, activation=\"softmax\")(model)\n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fit_predict(model, x_train, x_test, y, history):\n",
    "    \n",
    "    model.fit(x_train, y,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS, verbose=1,\n",
    "              validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "    return model.predict(x_test)\n",
    "\n",
    "\n",
    "# Get the list of different classes\n",
    "CLASSES_LIST = np.unique(y_train)\n",
    "n_out = len(CLASSES_LIST)\n",
    "print(CLASSES_LIST)\n",
    "\n",
    "# Convert clas string to index\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(CLASSES_LIST)\n",
    "y_train = le.transform(y_train) \n",
    "y_test = le.transform(y_test) \n",
    "train_y_cat = np_utils.to_categorical(y_train, n_out)\n",
    "\n",
    "# get the textual data in the correct format for NN\n",
    "#x_vec_train, x_vec_test = get_train_test(x_train, x_test)\n",
    "#print(len(x_vec_train), len(x_vec_test))\n",
    "\n",
    "# define the NN topology\n",
    "model = get_model()\n",
    "\n",
    "# Define training procedure\n",
    "history = TrainingHistory(x_test_tf, y_test, CLASSES_LIST)\n",
    "\n",
    "# Train and predict\n",
    "y_predicted = train_fit_predict(model, x_train_tf, x_test_tf, train_y_cat, history).argmax(1)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_predicted, \n",
    "                                              average='micro',\n",
    "                                              labels=[x for x in \n",
    "                                                      np.unique(y_train) \n",
    "                                                      if x not in ['CSDECMOTV']])\n",
    "\n",
    "print('p r f1 %.1f %.2f %.3f' % (np.average(p, weights=s)*100.0, \n",
    "                                 np.average(r, weights=s)*100.0, \n",
    "                                 np.average(f1, weights=s)*100.0))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_predicted, labels=[x for x in \n",
    "                                                       np.unique(y_train) \n",
    "                                                       if x not in ['CSDECMOTV']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN une matrice d’embedding basée sur TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create document vectors\n",
    "# YOUR CODE HERE\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "vectorizer.fit(x_train)\n",
    "x_train_counts = vectorizer.transform(x_train)\n",
    "x_test_counts = vectorizer.transform(x_test)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# With TF-IDF representation\n",
    "tf_transformer = TfidfTransformer()\n",
    "tfidf = tf_transformer.fit(x_train_counts)\n",
    "x_train_tf = tfidf.transform(x_train_counts)\n",
    "x_test_tf = tfidf.transform(x_test_counts)\n",
    "\n",
    "# Use x_train_tf as the embedding matrix\n",
    "embedding_matrix = x_train_tf.toarray().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_raw_text, test_raw_text):\n",
    "    \n",
    "    tokenizer = text.Tokenizer(num_words=MAX_WORDS)\n",
    "\n",
    "    tokenizer.fit_on_texts(list(train_raw_text))\n",
    "    train_tokenized = tokenizer.texts_to_sequences(train_raw_text)\n",
    "    test_tokenized = tokenizer.texts_to_sequences(test_raw_text)\n",
    "    return sequence.pad_sequences(train_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           sequence.pad_sequences(test_tokenized, maxlen=MAX_TEXT_LENGTH)\n",
    "\n",
    "\n",
    "\n",
    "def get_model_1(embedding_matrix):\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,))\n",
    "    model = Embedding(MAX_WORDS,\n",
    "                      EMBED_SIZE,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=MAX_TEXT_LENGTH,\n",
    "                      trainable=False)(inp)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Conv1D(filters=32, kernel_size=2, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=2)(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(NB_CLASS, activation=\"softmax\")(model)\n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 2785)         27850000  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500, 2785)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           178272    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              8193024   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 36,231,546\n",
      "Trainable params: 8,381,546\n",
      "Non-trainable params: 27,850,000\n",
      "_________________________________________________________________\n",
      "Train on 2506 samples, validate on 279 samples\n",
      "Epoch 1/20\n",
      "2506/2506 [==============================] - 75s 30ms/step - loss: 1.9075 - acc: 0.2785 - val_loss: 1.7477 - val_acc: 0.3226\n",
      "Epoch 2/20\n",
      "2506/2506 [==============================] - 75s 30ms/step - loss: 1.6159 - acc: 0.4146 - val_loss: 1.5954 - val_acc: 0.4301\n",
      "Epoch 3/20\n",
      "2506/2506 [==============================] - 71s 28ms/step - loss: 1.2364 - acc: 0.5626 - val_loss: 1.5320 - val_acc: 0.4158\n",
      "Epoch 4/20\n",
      "2506/2506 [==============================] - 79s 32ms/step - loss: 0.9128 - acc: 0.6875 - val_loss: 1.5104 - val_acc: 0.4480\n",
      "Epoch 5/20\n",
      "2506/2506 [==============================] - 77s 31ms/step - loss: 0.6597 - acc: 0.7682 - val_loss: 1.5632 - val_acc: 0.4803\n",
      "Epoch 6/20\n",
      "2506/2506 [==============================] - 80s 32ms/step - loss: 0.5368 - acc: 0.8204 - val_loss: 1.5880 - val_acc: 0.4624\n",
      "Epoch 7/20\n",
      "2506/2506 [==============================] - 77s 31ms/step - loss: 0.4217 - acc: 0.8551 - val_loss: 1.6701 - val_acc: 0.4659\n",
      "Epoch 8/20\n",
      "2506/2506 [==============================] - 75s 30ms/step - loss: 0.3461 - acc: 0.8855 - val_loss: 1.7087 - val_acc: 0.4695\n",
      "Epoch 9/20\n",
      "2506/2506 [==============================] - 81s 32ms/step - loss: 0.3043 - acc: 0.8986 - val_loss: 1.7512 - val_acc: 0.4982\n",
      "Epoch 10/20\n",
      "2506/2506 [==============================] - 75s 30ms/step - loss: 0.2641 - acc: 0.9118 - val_loss: 1.7011 - val_acc: 0.4875\n",
      "Epoch 11/20\n",
      "2506/2506 [==============================] - 88s 35ms/step - loss: 0.2366 - acc: 0.9194 - val_loss: 1.6310 - val_acc: 0.5090\n",
      "Epoch 12/20\n",
      "2506/2506 [==============================] - 78s 31ms/step - loss: 0.2235 - acc: 0.9250 - val_loss: 1.7433 - val_acc: 0.5161\n",
      "Epoch 13/20\n",
      "2506/2506 [==============================] - 84s 33ms/step - loss: 0.1795 - acc: 0.9465 - val_loss: 1.7258 - val_acc: 0.5125\n",
      "Epoch 14/20\n",
      "2506/2506 [==============================] - 74s 29ms/step - loss: 0.1608 - acc: 0.9477 - val_loss: 1.8630 - val_acc: 0.5090\n",
      "Epoch 15/20\n",
      "2506/2506 [==============================] - 80s 32ms/step - loss: 0.1528 - acc: 0.9489 - val_loss: 1.7329 - val_acc: 0.5376\n",
      "Epoch 16/20\n",
      "2506/2506 [==============================] - 75s 30ms/step - loss: 0.1615 - acc: 0.9453 - val_loss: 1.8650 - val_acc: 0.5125\n",
      "Epoch 17/20\n",
      "2506/2506 [==============================] - 76s 30ms/step - loss: 0.1442 - acc: 0.9473 - val_loss: 1.8215 - val_acc: 0.5269\n",
      "Epoch 18/20\n",
      "2506/2506 [==============================] - 73s 29ms/step - loss: 0.1322 - acc: 0.9565 - val_loss: 1.8405 - val_acc: 0.5305\n",
      "Epoch 19/20\n",
      "2506/2506 [==============================] - 80s 32ms/step - loss: 0.1170 - acc: 0.9593 - val_loss: 1.9441 - val_acc: 0.5197\n",
      "Epoch 20/20\n",
      "2506/2506 [==============================] - 69s 27ms/step - loss: 0.1202 - acc: 0.9633 - val_loss: 1.8539 - val_acc: 0.5197\n",
      "Test Accuracy: 0.6183644189383071\n",
      "p r f1 61.8 61.84 61.836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.38      0.46        45\n",
      "           1       0.91      0.88      0.89       128\n",
      "           2       0.69      0.72      0.70        96\n",
      "           3       0.53      0.62      0.57       104\n",
      "           4       0.52      0.62      0.56       119\n",
      "           5       0.67      0.40      0.50        30\n",
      "           6       0.55      0.70      0.62        40\n",
      "           7       0.24      0.26      0.25        50\n",
      "           8       0.96      0.84      0.90        31\n",
      "           9       0.50      0.30      0.37        54\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       697\n",
      "   macro avg       0.62      0.57      0.58       697\n",
      "weighted avg       0.63      0.62      0.62       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE = len(x_train)\n",
    "MAX_WORDS = 10000\n",
    "\n",
    "x_vec_train, x_vec_test = get_train_test(x_train, x_test)\n",
    "model = get_model_1(embedding_matrix)\n",
    "\n",
    "# Define training procedure\n",
    "history = TrainingHistory(x_vec_test, y_test, CLASSES_LIST)\n",
    "\n",
    "# Train and predict\n",
    "y_predicted = train_fit_predict(model, x_vec_train, x_vec_test, train_y_cat, history).argmax(1)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_predicted, \n",
    "                                              average='micro',\n",
    "                                              labels=[x for x in \n",
    "                                                      np.unique(y_train) \n",
    "                                                      if x not in ['CSDECMOTV']])\n",
    "\n",
    "print('p r f1 %.1f %.2f %.3f' % (np.average(p, weights=s)*100.0, \n",
    "                                 np.average(r, weights=s)*100.0, \n",
    "                                 np.average(f1, weights=s)*100.0))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_predicted, labels=[x for x in \n",
    "                                                       np.unique(y_train) \n",
    "                                                       if x not in ['CSDECMOTV']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN avec word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the texts into one file\n",
    "path = \"Tobacco3482-OCR/\"\n",
    "classes = os.listdir(path)\n",
    "\n",
    "vector_file = open('text_pure_nolabel.txt', 'a')\n",
    "for cls in classes:\n",
    "    files = os.listdir(path + cls)\n",
    "    for file in files:\n",
    "        with open(path + cls + \"/\" + file, 'r') as f:\n",
    "            txt = f.read()\n",
    "            txt = txt.replace(\"\\n\", \" \")\n",
    "            vector_file.writelines((txt,'\\n'))\n",
    "vector_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-fb79bc46a04e>\", line 5, in <module>\n",
      "    model_word2vec = Word2Vec(LineSentence(file_path), workers=4, sg=1, size=150, iter=100)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/word2vec.py\", line 767, in __init__\n",
      "    fast_version=FAST_VERSION)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\", line 763, in __init__\n",
      "    end_alpha=self.min_alpha, compute_loss=compute_loss)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/word2vec.py\", line 892, in train\n",
      "    queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\", line 1081, in train\n",
      "    **kwargs)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\", line 553, in train\n",
      "    total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\", line 489, in _train_epoch\n",
      "    report_delay=report_delay, is_corpus_file_mode=False)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\", line 346, in _log_epoch_progress\n",
      "    report = progress_queue.get()  # blocks if workers too slow\n",
      "  File \"/usr/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yibing/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1488, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1446, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 378, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 365, in normpath\n",
      "    path = sep*initial_slashes + path\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "file_path = 'text_pure_nolabel.txt'\n",
    "\n",
    "# Skipgram model\n",
    "#tic = time.time()\n",
    "model_word2vec = Word2Vec(LineSentence(file_path), workers=4, sg=1, size=150, iter=100)\n",
    "#toc = time.time()\n",
    "#print(\"Time used to train a word2vec_skipgram word representation model: \" + str(toc - tic) + \"s\")\n",
    "\n",
    "# Sauvegarder le modèle et les vecteurs entraînés\n",
    "model_word2vec.save('word2vec_skip.model')\n",
    "model_word2vec.wv.save_word2vec_format('word2vec_skip.txt', binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "MAX_TEXT_LENGTH = 500\n",
    "MAX_WORDS = 10000\n",
    "EMBED_SIZE = 150\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.1\n",
    "NB_CLASS = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_index(vectors_file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(vectors_file_path, 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        #print(first_line)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "            \n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    \n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def get_embedding_matrix(word_index, embedding_index):\n",
    "    print('Building embedding matrix...')\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('Embedding matrix built.')        \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_raw_text, test_raw_text):\n",
    "    \n",
    "    tokenizer = text.Tokenizer(num_words=MAX_WORDS)\n",
    "\n",
    "    tokenizer.fit_on_texts(list(train_raw_text))\n",
    "    word_index = tokenizer.word_index\n",
    "    train_tokenized = tokenizer.texts_to_sequences(train_raw_text)\n",
    "    test_tokenized = tokenizer.texts_to_sequences(test_raw_text)\n",
    "    return sequence.pad_sequences(train_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           sequence.pad_sequences(test_tokenized, maxlen=MAX_TEXT_LENGTH), \\\n",
    "           word_index\n",
    "\n",
    "\n",
    "def get_model_2(embedding_matrix, word_index, print_sum=True):\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,))\n",
    "\n",
    "    model = Embedding(len(word_index) + 1,\n",
    "                      EMBED_SIZE,\n",
    "                      weights=[embedding_matrix],\n",
    "                      input_length=MAX_TEXT_LENGTH,\n",
    "                      trainable=False)(inp)\n",
    "    \n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Conv1D(filters=64, kernel_size=5, padding='same', activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = MaxPooling1D(pool_size=2)(model)\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation='relu')(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    model = Dense(NB_CLASS, activation=\"softmax\")(model)\n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    if print_sum:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16356 word vectors.\n",
      "Building embedding matrix...\n",
      "Embedding matrix built.\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 500, 150)          11186850  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 500, 150)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 500, 64)           48064     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1024)              16385024  \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 27,630,188\n",
      "Trainable params: 16,443,338\n",
      "Non-trainable params: 11,186,850\n",
      "_________________________________________________________________\n",
      "Train on 2506 samples, validate on 279 samples\n",
      "Epoch 1/20\n",
      "2506/2506 [==============================] - 50s 20ms/step - loss: 2.2101 - acc: 0.2785 - val_loss: 1.9412 - val_acc: 0.3907\n",
      "Epoch 2/20\n",
      "2506/2506 [==============================] - 42s 17ms/step - loss: 1.4763 - acc: 0.4645 - val_loss: 1.5529 - val_acc: 0.4194\n",
      "Epoch 3/20\n",
      "2506/2506 [==============================] - 44s 18ms/step - loss: 1.0982 - acc: 0.6065 - val_loss: 1.3461 - val_acc: 0.5412\n",
      "Epoch 4/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.8493 - acc: 0.7007 - val_loss: 1.2295 - val_acc: 0.5627\n",
      "Epoch 5/20\n",
      "2506/2506 [==============================] - 46s 18ms/step - loss: 0.7258 - acc: 0.7474 - val_loss: 1.1888 - val_acc: 0.5771\n",
      "Epoch 6/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.5461 - acc: 0.8045 - val_loss: 1.0226 - val_acc: 0.6237\n",
      "Epoch 7/20\n",
      "2506/2506 [==============================] - 44s 18ms/step - loss: 0.4674 - acc: 0.8416 - val_loss: 1.0182 - val_acc: 0.6703\n",
      "Epoch 8/20\n",
      "2506/2506 [==============================] - 44s 18ms/step - loss: 0.3823 - acc: 0.8679 - val_loss: 0.9793 - val_acc: 0.6703\n",
      "Epoch 9/20\n",
      "2506/2506 [==============================] - 43s 17ms/step - loss: 0.3845 - acc: 0.8603 - val_loss: 0.9632 - val_acc: 0.6523\n",
      "Epoch 10/20\n",
      "2506/2506 [==============================] - 42s 17ms/step - loss: 0.3541 - acc: 0.8767 - val_loss: 0.9928 - val_acc: 0.6416\n",
      "Epoch 11/20\n",
      "2506/2506 [==============================] - 43s 17ms/step - loss: 0.2773 - acc: 0.8951 - val_loss: 1.0325 - val_acc: 0.6201\n",
      "Epoch 12/20\n",
      "2506/2506 [==============================] - 48s 19ms/step - loss: 0.2694 - acc: 0.9042 - val_loss: 0.9790 - val_acc: 0.6452\n",
      "Epoch 13/20\n",
      "2506/2506 [==============================] - 43s 17ms/step - loss: 0.2403 - acc: 0.9138 - val_loss: 1.0264 - val_acc: 0.6380\n",
      "Epoch 14/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.2588 - acc: 0.9110 - val_loss: 1.0271 - val_acc: 0.6523\n",
      "Epoch 15/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.2323 - acc: 0.9250 - val_loss: 0.9940 - val_acc: 0.6380\n",
      "Epoch 16/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.2139 - acc: 0.9286 - val_loss: 1.0685 - val_acc: 0.6738\n",
      "Epoch 17/20\n",
      "2506/2506 [==============================] - 46s 18ms/step - loss: 0.2035 - acc: 0.9326 - val_loss: 1.0657 - val_acc: 0.6703\n",
      "Epoch 18/20\n",
      "2506/2506 [==============================] - 47s 19ms/step - loss: 0.1896 - acc: 0.9346 - val_loss: 1.0102 - val_acc: 0.6667\n",
      "Epoch 19/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.1832 - acc: 0.9354 - val_loss: 1.0853 - val_acc: 0.6559\n",
      "Epoch 20/20\n",
      "2506/2506 [==============================] - 45s 18ms/step - loss: 0.2012 - acc: 0.9366 - val_loss: 0.9752 - val_acc: 0.7061\n",
      "Test Accuracy: 0.7187948350071736\n",
      "p r f1 71.9 71.88 71.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59        45\n",
      "           1       0.97      0.96      0.96       128\n",
      "           2       0.83      0.67      0.74        96\n",
      "           3       0.74      0.58      0.65       104\n",
      "           4       0.67      0.87      0.76       119\n",
      "           5       0.64      0.70      0.67        30\n",
      "           6       0.57      0.82      0.67        40\n",
      "           7       0.36      0.52      0.43        50\n",
      "           8       1.00      0.90      0.95        31\n",
      "           9       0.83      0.28      0.42        54\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       697\n",
      "   macro avg       0.72      0.69      0.68       697\n",
      "weighted avg       0.75      0.72      0.72       697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "x_vec_train, x_vec_test, word_index = get_train_test(x_train, x_test)\n",
    "\n",
    "vectors_file_path = 'word2vec_skip.txt'\n",
    "embedding_index = get_embedding_index(vectors_file_path)\n",
    "embedding_matrix = get_embedding_matrix(word_index, embedding_index)\n",
    "print('Building model...')\n",
    "\n",
    "#x_vec_train, x_vec_test = get_train_test(x_train, x_test)\n",
    "model = get_model_2(embedding_matrix, word_index)\n",
    "\n",
    "history = TrainingHistory(x_vec_test, y_test, CLASSES_LIST)\n",
    "y_predicted = train_fit_predict(model, x_vec_train, x_vec_test, train_y_cat, history).argmax(1)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_predicted, \n",
    "                                              average='micro',\n",
    "                                              labels=[x for x in \n",
    "                                                      np.unique(y_train) \n",
    "                                                      if x not in ['CSDECMOTV']])\n",
    "\n",
    "print('p r f1 %.1f %.2f %.3f' % (np.average(p, weights=s)*100.0, \n",
    "                                 np.average(r, weights=s)*100.0, \n",
    "                                 np.average(f1, weights=s)*100.0))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_predicted, labels=[x for x in \n",
    "                                                       np.unique(y_train) \n",
    "                                                       if x not in ['CSDECMOTV']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
